# üìä Capacidades de Anal√≠tica en Mastra

## Resumen Ejecutivo

Mastra proporciona un ecosistema completo de observabilidad y anal√≠tica para aplicaciones de AI, permitiendo medir, monitorear y optimizar el rendimiento de agentes, workflows y herramientas en tiempo real.

## üéØ 1. Sistema de Evaluaciones (Evals)

### ¬øQu√© son las Evaluaciones?

Las evaluaciones son pruebas automatizadas que miden la calidad de las respuestas de los agentes usando m√©todos basados en modelos, reglas y estad√≠sticas. Cada evaluaci√≥n devuelve una puntuaci√≥n normalizada entre 0-1.

### Categor√≠as de M√©tricas

#### üìè Precisi√≥n y Confiabilidad
| M√©trica | Descripci√≥n | Caso de Uso |
|---------|-------------|-------------|
| **Hallucination** | Detecta afirmaciones no presentes en el contexto | Verificar que el agente no invente informaci√≥n |
| **Faithfulness** | Mide fidelidad al contexto proporcionado | Asegurar respuestas basadas en fuentes |
| **Content Similarity** | Eval√∫a consistencia entre respuestas | Verificar coherencia en m√∫ltiples consultas |
| **Completeness** | Verifica informaci√≥n completa | Asegurar respuestas exhaustivas |
| **Answer Relevancy** | Eval√∫a relevancia de respuestas | Medir qu√© tan bien se responde la pregunta |

#### üß† Comprensi√≥n del Contexto
| M√©trica | Descripci√≥n | Caso de Uso |
|---------|-------------|-------------|
| **Context Position** | Analiza ubicaci√≥n del contexto | Optimizar estructura de respuestas |
| **Context Precision** | Eval√∫a agrupaci√≥n l√≥gica | Mejorar coherencia narrativa |
| **Context Relevancy** | Mide uso apropiado del contexto | Evitar informaci√≥n irrelevante |
| **Contextual Recall** | Eval√∫a exhaustividad | Asegurar uso completo del contexto |

#### ‚ú® Calidad de Salida
| M√©trica | Descripci√≥n | Caso de Uso |
|---------|-------------|-------------|
| **Tone Consistency** | Mide consistencia de tono | Mantener voz de marca |
| **Toxicity** | Detecta contenido inapropiado | Filtrar respuestas da√±inas |
| **Bias** | Identifica sesgos | Asegurar respuestas equitativas |
| **Prompt Alignment** | Verifica adherencia a instrucciones | Cumplir requerimientos espec√≠ficos |

### Implementaci√≥n de Evaluaciones

```typescript
import { Agent } from "@mastra/core/agent";
import { SummarizationMetric } from "@mastra/evals/llm";
import { ContentSimilarityMetric, ToneConsistencyMetric } from "@mastra/evals/nlp";

export const myAgent = new Agent({
  name: "ContentWriter",
  instructions: "You are a content writer",
  model: openai("gpt-4o"),
  evals: {
    summarization: new SummarizationMetric(model),
    contentSimilarity: new ContentSimilarityMetric(),
    tone: new ToneConsistencyMetric(),
  },
});
```

## üìà 2. Observabilidad y Telemetr√≠a

### OpenTelemetry (OTLP)

Mastra captura autom√°ticamente trazas de todas las operaciones principales:

```typescript
export const mastra = new Mastra({
  telemetry: {
    serviceName: "mi-aplicacion",
    enabled: true,
    sampling: {
      type: "ratio",
      probability: 0.5 // Captura 50% de las trazas
    },
    export: {
      type: "otlp",
      endpoint: "http://localhost:4318" // SigNoz, Jaeger, etc.
    }
  }
});
```

### M√©tricas Capturadas Autom√°ticamente

#### ü§ñ Agentes
- Tiempo de respuesta total
- Tokens consumidos (entrada/salida)
- N√∫mero de pasos ejecutados
- Herramientas invocadas
- Tasa de √©xito/error

#### ‚öôÔ∏è Workflows
- Duraci√≥n por paso
- Flujo de ejecuci√≥n
- Datos entrada/salida
- Errores y reintentos
- Estado final

#### üîß Herramientas
- Frecuencia de uso
- Tiempo de ejecuci√≥n
- Tasa de √©xito
- Par√°metros utilizados
- Errores comunes

#### üåê Integraciones
- Latencia de API
- Tasa de respuesta
- C√≥digos de estado HTTP
- Tama√±o de payload
- Timeouts

## üìù 3. Sistema de Logging

### Configuraci√≥n de Logs

```typescript
import { PinoLogger } from "@mastra/loggers";

export const mastra = new Mastra({
  logger: new PinoLogger({
    name: "Mastra",
    level: "info", // debug, info, warn, error
    transports: {
      console: true,
      file: new FileTransport({ path: "logs/app.log" }),
      upstash: new UpstashTransport({
        listName: "production-logs",
        upstashUrl: process.env.UPSTASH_URL,
        upstashToken: process.env.UPSTASH_TOKEN,
      })
    }
  }),
});
```

### Estructura de Logs

```json
{
  "timestamp": "2025-01-14T10:30:00Z",
  "level": "INFO",
  "message": "Agent completed task",
  "destinationPath": "agent-actions",
  "type": "AGENT",
  "runId": "run_abc123",
  "metadata": {
    "agentId": "assistant",
    "duration": 1234,
    "tokensUsed": 567
  }
}
```

## üñ•Ô∏è 4. Dashboards de Monitoreo

### Mastra Dev (Desarrollo Local)

Al ejecutar `mastra dev`, obtienes acceso a un playground completo en `http://localhost:4111/`:

#### Panel de Agentes
- **Chat Interactivo**: Prueba conversaciones en tiempo real
- **Configuraci√≥n Din√°mica**: Ajusta temperatura, top-p, max tokens
- **Trazas Detalladas**: Ve cada paso de la ejecuci√≥n
- **Evaluaciones en Vivo**: Puntuaciones instant√°neas por respuesta
- **Historial**: Revisa conversaciones anteriores

#### Panel de Workflows
- **Visualizaci√≥n de Flujo**: Diagrama interactivo del workflow
- **Ejecuci√≥n Paso a Paso**: Monitorea progreso en tiempo real
- **Datos I/O**: Inspecciona entradas y salidas de cada paso
- **M√©tricas de Rendimiento**: Tiempo por paso, uso de recursos
- **Debugging**: Identifica cuellos de botella y errores

#### Panel de Herramientas
- **Pruebas Aisladas**: Ejecuta herramientas individualmente
- **Validaci√≥n de Schema**: Verifica inputs/outputs
- **Estad√≠sticas de Uso**: Qu√© agentes usan cada herramienta
- **Rendimiento**: Tiempo promedio de respuesta

### Mastra Cloud (Producci√≥n)

El dashboard de producci√≥n ofrece:

#### Overview
- Estado actual del deployment
- URLs y endpoints activos
- Variables de entorno configuradas
- Agentes y workflows conectados

#### Deployments
- Historial de despliegues
- Logs de build detallados
- Estado por rama git
- Rollback r√°pido

#### Logs
- Filtrado por severidad
- B√∫squeda en tiempo real
- Exportaci√≥n de logs
- Alertas configurables

#### Playground
- Prueba agentes en producci√≥n
- Monitorea evaluaciones en vivo
- Ejecuta workflows manualmente
- Inspecciona trazas detalladas

## üîç 5. M√©tricas de Rendimiento

### Latencia y Tiempo de Respuesta

```typescript
// M√©tricas autom√°ticas capturadas:
{
  "agent.response_time": 1234, // ms
  "llm.latency": 987,          // ms
  "tool.execution_time": 123,   // ms
  "workflow.total_duration": 5678 // ms
}
```

### Uso de Recursos

```typescript
{
  "tokens.input": 234,
  "tokens.output": 567,
  "tokens.total": 801,
  "cost.estimated": 0.0234, // USD
  "memory.used": 45.6,      // MB
  "api.calls": 12
}
```

### Tasas de √âxito y Error

```typescript
{
  "success_rate": 0.95,      // 95%
  "error_rate": 0.05,        // 5%
  "retry_rate": 0.12,        // 12%
  "timeout_rate": 0.02,      // 2%
  "errors_by_type": {
    "rate_limit": 3,
    "network": 2,
    "validation": 1
  }
}
```

## üìä 6. Anal√≠tica Avanzada

### An√°lisis de Conversaciones

- **Longitud promedio**: Tokens por mensaje
- **Tiempo de respuesta**: P50, P90, P99
- **Turnos por sesi√≥n**: Interacciones promedio
- **Temas frecuentes**: An√°lisis de contenido
- **Sentimiento**: Positivo/negativo/neutral

### An√°lisis de Calidad

- **Coherencia**: Consistencia entre respuestas
- **Relevancia**: Alineaci√≥n con consultas
- **Completitud**: Informaci√≥n faltante
- **Claridad**: Legibilidad y estructura
- **Accuracy**: Precisi√≥n factual

### An√°lisis de Costos

- **Costo por conversaci√≥n**: Desglose detallado
- **Modelos m√°s costosos**: Identificar gastos
- **Optimizaci√≥n**: Sugerencias de ahorro
- **Proyecciones**: Estimaciones futuras
- **ROI**: Retorno de inversi√≥n

## üîß 7. Integraciones con Proveedores

### Proveedores Soportados

| Proveedor | Especialidad | Configuraci√≥n |
|-----------|--------------|---------------|
| **SigNoz** | Trazas y m√©tricas open source | `endpoint: "http://signoz:4318"` |
| **Langfuse** | LLM observability | `new LangfuseExporter({...})` |
| **Braintrust** | Evaluaci√≥n continua | API key required |
| **LangSmith** | Debug de cadenas LLM | Project ID needed |
| **New Relic** | APM completo | License key |
| **Datadog** | Monitoreo empresarial | API key |

### Ejemplo de Integraci√≥n

```typescript
// Langfuse para Next.js
import { LangfuseExporter } from "langfuse-vercel";

export function register() {
  const exporter = new LangfuseExporter({
    publicKey: process.env.LANGFUSE_PUBLIC_KEY,
    secretKey: process.env.LANGFUSE_SECRET_KEY,
    baseUrl: "https://cloud.langfuse.com"
  });

  const sdk = new NodeSDK({
    resource: resourceFromAttributes({
      [ATTR_SERVICE_NAME]: "karmatic-ai",
    }),
    traceExporter: exporter,
  });

  sdk.start();
}
```

## üí° 8. Casos de Uso Pr√°cticos

### 1. Optimizaci√≥n de Costos

```typescript
// Identificar llamadas costosas
const costAnalysis = await mastra.telemetry.query({
  metric: "tokens.total",
  groupBy: "agent.id",
  orderBy: "cost.estimated DESC",
  limit: 10
});

// Implementar cach√© para respuestas frecuentes
const cachedResponse = await cache.get(queryHash);
if (!cachedResponse) {
  const response = await agent.generate(query);
  await cache.set(queryHash, response, { ttl: 3600 });
}
```

### 2. Detecci√≥n de Degradaci√≥n

```typescript
// Monitorear puntuaciones de evaluaci√≥n
const evalTrend = await mastra.evals.getTrend({
  metric: "faithfulness",
  period: "7d",
  threshold: 0.8
});

if (evalTrend.declining) {
  // Alertar al equipo
  await notify.slack({
    channel: "#ai-alerts",
    message: "‚ö†Ô∏è Faithfulness score declining: " + evalTrend.current
  });
}
```

### 3. A/B Testing de Prompts

```typescript
// Configurar experimento
const experiment = {
  control: "You are a helpful assistant",
  variant: "You are an expert assistant with deep knowledge"
};

// Ejecutar pruebas
const results = await mastra.experiments.run({
  agent: "assistant",
  prompts: experiment,
  samples: 1000,
  metrics: ["relevancy", "completeness", "tone"]
});

// Analizar resultados
console.log("Winner:", results.winner);
console.log("Improvement:", results.improvement);
```

### 4. Debugging en Producci√≥n

```typescript
// Buscar conversaci√≥n problem√°tica
const problematicThread = await mastra.logs.search({
  level: "ERROR",
  type: "AGENT",
  timeRange: "1h",
  contains: "timeout"
});

// Reproducir con trazas detalladas
const replay = await mastra.debug.replay({
  threadId: problematicThread.id,
  enableTracing: true,
  verbosity: "debug"
});
```

## üöÄ Mejores Pr√°cticas

1. **Configura Evaluaciones Desde el Inicio**
   - Define m√©tricas clave para tu caso de uso
   - Establece umbrales de calidad m√≠nimos
   - Automatiza alertas para degradaci√≥n

2. **Usa Sampling Inteligente**
   - No traces 100% en producci√≥n (costoso)
   - Aumenta sampling para usuarios nuevos
   - Captura 100% de errores

3. **Implementa Dashboards Personalizados**
   - KPIs espec√≠ficos de tu negocio
   - Alertas proactivas
   - Reportes ejecutivos

4. **Optimiza Continuamente**
   - Revisa m√©tricas semanalmente
   - Ajusta prompts bas√°ndote en datos
   - Experimenta con nuevos modelos

---

**√öltima actualizaci√≥n**: Enero 2025